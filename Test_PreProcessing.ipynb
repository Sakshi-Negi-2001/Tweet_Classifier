{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "from string import punctuation\n",
    "from time import process_time\n",
    "from nltk import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import unicodedata\n",
    "import preprocessor as p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Preprocess_Data():\n",
    "    \n",
    "    # ----------------------------------------- Constructor -----------------------------------------\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.punctuation = set(punctuation)\n",
    "        self.lemmatizer = WordNetLemmatizer()\n",
    "        p.set_options(p.OPT.URL, p.OPT.EMOJI, p.OPT.MENTION, p.OPT.RESERVED, p.OPT.SMILEY)\n",
    "        self.stopword_list = set(stopwords.words('english'))\n",
    "        unwanted_stopwords = {'no', 'nor', 'not', 'ain', 'aren', \"aren't\", 'couldn', 'what', 'which', 'who',\n",
    "                              'whom', 'why', 'how', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn',\n",
    "                              \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn',\n",
    "                              \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn',\n",
    "                              \"shouldn't\", 'wasn',\"wasn't\",'weren', \"weren't\", 'won', \"won't\", 'wouldn',\n",
    "                              \"wouldn't\", 'don', \"don't\"}\n",
    "\n",
    "        self.stopword_list = [x for x in self.stopword_list if x not in unwanted_stopwords]\n",
    "       \n",
    "    \n",
    "    # ----------------------------------------- Read Data -----------------------------------------\n",
    "    \n",
    "    def read_data(self, path):\n",
    "        df = pd.read_csv(path, usecols=['user_screen_name', 'text', 'hashtags'])\n",
    "        return df\n",
    "    \n",
    "    \n",
    "    # ----------------------------------------- Clean Data -----------------------------------------\n",
    "    \n",
    "    def clean_data(self, tweets):\n",
    "        cleaned_tweets = []\n",
    "        for text in tweets:\n",
    "            # Clean tweet\n",
    "            text = p.clean(text)\n",
    "            # Remove special characters\n",
    "            text = re.sub(r'(\\\\x(.)*)', '',text)\n",
    "            text = re.sub(r'\\\\n|\\\\t|\\\\n\\\\n', ' ', text)\n",
    "            text = re.sub(\"[@#$%^&*)(}{|/><=+=_:\\\"\\\\\\\\]+\",\" \",text).strip() \n",
    "            #Remove punctuation marks\n",
    "            text = \"\".join(x for x in text if x not in self.punctuation)\n",
    "            # Remove accented words\n",
    "            text = unicodedata.normalize('NFKD', text).encode('ascii', 'ignore').decode('utf-8', 'ignore')\n",
    "            # Splitting Hashtag words\n",
    "            text = \" \".join([x for x in re.split('([A-Z][a-z]+)', text) if x])\n",
    "            # Remove long spaces\n",
    "            pattern = r'^\\s*|\\s\\s*'\n",
    "            text = re.sub(pattern, ' ', text).strip()\n",
    "            # Remove numbers\n",
    "            text = re.sub('[0-9]+', '', text)\n",
    "            \n",
    "            cleaned_tweets.append(text)\n",
    "        \n",
    "        return cleaned_tweets\n",
    "    \n",
    "    \n",
    "    # ----------------------------------------- Preprocess Data -----------------------------------------\n",
    "    \n",
    "    def preprocess_data(self, tweets):\n",
    "        preprocessed_tweets = []\n",
    "        for text in tweets:\n",
    "            \n",
    "            # Remove stopwords\n",
    "            text = \" \".join(x for x in text.lower().split() if x not in self.stopword_list)\n",
    "            \n",
    "            # Text Lemmatization\n",
    "            lemmatized_words = []\n",
    "            for word in text.split():\n",
    "                word1 = self.lemmatizer.lemmatize(word, pos=\"n\")\n",
    "                word2 = self.lemmatizer.lemmatize(word1, pos=\"v\")\n",
    "                word3 = self.lemmatizer.lemmatize(word2, pos=(\"a\"))\n",
    "                lemmatized_words.append(word3)\n",
    "            text = \" \".join(x for x in lemmatized_words)\n",
    "            \n",
    "            preprocessed_tweets.append(text)\n",
    "            \n",
    "        return preprocessed_tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "pre = Preprocess_Data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_screen_name</th>\n",
       "      <th>text</th>\n",
       "      <th>hashtags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Bhupinder295</td>\n",
       "      <td>RT @Tractor2twitr_P: RO systems which wr once ...</td>\n",
       "      <td>['FarmersProtest', 'ZiraSanjhaMorcha']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Cultural_Pendu</td>\n",
       "      <td>RT @_MohitGahlot_: Those who talk of doubling ...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Jag22946452</td>\n",
       "      <td>RT @Tractor2twitr_P: RO systems which wr once ...</td>\n",
       "      <td>['FarmersProtest', 'ZiraSanjhaMorcha']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Aman_Kaur45</td>\n",
       "      <td>RT @_MohitGahlot_: Those who talk of doubling ...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Sandhu_Deep1</td>\n",
       "      <td>RT @_MohitGahlot_: Those who talk of doubling ...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  user_screen_name                                               text  \\\n",
       "0     Bhupinder295  RT @Tractor2twitr_P: RO systems which wr once ...   \n",
       "1   Cultural_Pendu  RT @_MohitGahlot_: Those who talk of doubling ...   \n",
       "2      Jag22946452  RT @Tractor2twitr_P: RO systems which wr once ...   \n",
       "3      Aman_Kaur45  RT @_MohitGahlot_: Those who talk of doubling ...   \n",
       "4     Sandhu_Deep1  RT @_MohitGahlot_: Those who talk of doubling ...   \n",
       "\n",
       "                                 hashtags  \n",
       "0  ['FarmersProtest', 'ZiraSanjhaMorcha']  \n",
       "1                                      []  \n",
       "2  ['FarmersProtest', 'ZiraSanjhaMorcha']  \n",
       "3                                      []  \n",
       "4                                      []  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_path = './raw_tweets.csv'\n",
    "output_path = './processed_tweets.csv'\n",
    "\n",
    "data = pre.read_data(input_path)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['RT @Tractor2twitr_P: RO systems which wr once part of #FarmersProtest r being installed in #ZiraSanjhaMorcha .\\n\\nToxic pollution by Malbros…',\n",
       " 'RT @_MohitGahlot_: Those who talk of doubling the income, are not even able to give their respect fund to the farmers...\\n\\nApart from the po…']"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_tweets = data.text.values.tolist()\n",
    "raw_tweets[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['RO systems which wr once part of Farmers Protest r being installed in Zira Sanjha Morcha Toxic pollution by Malbros',\n",
       " 'Those who talk of doubling the income are not even able to give their respect fund to the farmers Apart from the po']"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned_tweets = pre.clean_data(raw_tweets)\n",
    "cleaned_tweets[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ro system which wr part farmer protest r instal zira sanjha morcha toxic pollution malbros',\n",
       " 'who talk double income not even able give respect fund farmer apart po']"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocess_tweets = pre.preprocess_data(cleaned_tweets)\n",
    "preprocess_tweets[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "      <th>hashtags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ro system which wr part farmer protest r insta...</td>\n",
       "      <td>['FarmersProtest', 'ZiraSanjhaMorcha']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>who talk double income not even able give resp...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ro system which wr part farmer protest r insta...</td>\n",
       "      <td>['FarmersProtest', 'ZiraSanjhaMorcha']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>who talk double income not even able give resp...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>who talk double income not even able give resp...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               tweet  \\\n",
       "0  ro system which wr part farmer protest r insta...   \n",
       "1  who talk double income not even able give resp...   \n",
       "2  ro system which wr part farmer protest r insta...   \n",
       "3  who talk double income not even able give resp...   \n",
       "4  who talk double income not even able give resp...   \n",
       "\n",
       "                                 hashtags  \n",
       "0  ['FarmersProtest', 'ZiraSanjhaMorcha']  \n",
       "1                                      []  \n",
       "2  ['FarmersProtest', 'ZiraSanjhaMorcha']  \n",
       "3                                      []  \n",
       "4                                      []  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1 = pd.DataFrame(columns = ['tweet','hashtags'])\n",
    "\n",
    "f1['tweet'] = pd.Series(preprocess_tweets)\n",
    "f1['hashtags'] = data['hashtags']\n",
    "\n",
    "f1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, row in f1.iterrows():\n",
    "    if (row['tweet'] == ''):\n",
    "        f1 = f1.drop(index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "      <th>hashtags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ro system which wr part farmer protest r insta...</td>\n",
       "      <td>['FarmersProtest', 'ZiraSanjhaMorcha']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>who talk double income not even able give resp...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ro system which wr part farmer protest r insta...</td>\n",
       "      <td>['FarmersProtest', 'ZiraSanjhaMorcha']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>who talk double income not even able give resp...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>who talk double income not even able give resp...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               tweet  \\\n",
       "0  ro system which wr part farmer protest r insta...   \n",
       "1  who talk double income not even able give resp...   \n",
       "2  ro system which wr part farmer protest r insta...   \n",
       "3  who talk double income not even able give resp...   \n",
       "4  who talk double income not even able give resp...   \n",
       "\n",
       "                                 hashtags  \n",
       "0  ['FarmersProtest', 'ZiraSanjhaMorcha']  \n",
       "1                                      []  \n",
       "2  ['FarmersProtest', 'ZiraSanjhaMorcha']  \n",
       "3                                      []  \n",
       "4                                      []  "
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# f1.to_csv('./original/test.csv')\n",
    "f1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(180, 2)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = f1.drop_duplicates(subset=['hashtags'])\n",
    "x.reset_index(inplace=True)\n",
    "x = x.drop('index', axis=1)\n",
    "x.to_csv('./original/test.csv')\n",
    "x.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11.0 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0 (main, Oct 24 2022, 18:26:48) [MSC v.1933 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5238573367df39f7286bb46f9ff5f08f63a01a80960060ce41e3c79b190280fa"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
